{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigendecompositions\n",
    "###  eigenvalue  eigendecomposition and singular value decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Data matrix](#Data-Matrix)\n",
    " - [Centering the Data](#Centering-the-data)\n",
    "- [The covariance matrix](#the-covariance-matrix)\n",
    "     - [Eigenvalues](#Eigenvalues)\n",
    "     - [Eigenvectors and right eigenvectors](#Eigenvectors-and-right-eigenvectors)\n",
    "- [The kernel matrix](#the-kernel-matrix)\n",
    "  - [Eigenvalues and Singular Values](#Eigenvalues-and-Singular-Values)\n",
    "  - [Eigenvectors and left eigenvectors](#Eigenvectors-and-left-eigenvectors)\n",
    "- [Singular Value Decomposition](#Singular-value-decomposition)\n",
    "  - [Singular Values](#Singular-values)\n",
    "  - [Eigenvectors](#Dual)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example :\n",
    "###### Four examples with dimension two\n",
    "\n",
    "\n",
    "$$\n",
    "       \\begin{array}{c|cc}\n",
    "       & X_1 & X_2 \\\\\\\\ \\hline\n",
    "\\mathbf{x}_1  & 1 & 2 \\\\\\\\\n",
    "\\mathbf{x}_2  & 3 & 4 \\\\\\\\\n",
    "\\mathbf{x}_3 & 3 & 1  \\\\\\\\\n",
    "\\mathbf{x}_4 & 1 & 1  \\\\\\\\\n",
    "\\end{array}\n",
    "$$   \n",
    "With the $4 \\times 2$ data matrix $\\mathbf{X}$ \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate\n",
    "1.  the mean vector $\\boldsymbol{\\mu}$   \n",
    "2.  the covariance matrix $\\boldsymbol{\\Sigma}$ \n",
    "3.  $\\mathbf{Z}= \\mathbf{X} - \\mathbf{1}_4  \\boldsymbol{\\mu}^T$. Explain the geometric meaning of the operation.\n",
    "4.  What is the result of $\\mathbf{Z}^T \\mathbf{Z}$\n",
    "\n",
    "Note: $\\mathbf{1}_4$ is a vector of ones with dimension 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [3, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The data set\n",
    "X=np.array([[1,2],[3,4],[3, 1],[1,1]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The mean vector [2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Answer to question 1\n",
    "mu=np.mean(X,0)\n",
    "print(' The mean vector', mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]]\n",
      "[[-1.  0.]\n",
      " [ 1.  2.]\n",
      " [ 1. -1.]\n",
      " [-1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "# Answer to question 3\n",
    "L=np.size(X,0)\n",
    "\n",
    "H=np.ones((L,1))*mu\n",
    "print(H)\n",
    "Z=X-H\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2.],\n",
       "       [2., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer to question 4)  (scatter matrix)\n",
    "Z1=Z.transpose()\n",
    "S=np.dot(Z1,Z)\n",
    "S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix ( Sigma on the slides)\n",
    "C= (1/4)*S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. what is the difference between scatter matrix  $\\mathbf{S}$and covariance matrix  $\\mathbf{C}$?  Write down the definitions of both.\n",
    "2. Another similar matrix  is the correlation matrix.  Its non-normalized form is defined as $ \\mathbf{R} =\\mathbf{X}^T \\mathbf{X}$. \n",
    "    * What is the dimension of $\\mathbf{R}$\n",
    "    * Write down the expression to compute each entry of $\\mathbf{R}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvectors \n",
      " [[-0.85065081 -0.52573111]\n",
      " [ 0.52573111 -0.85065081]] \n",
      " eigenvalues \n",
      " [2.76393202 7.23606798]\n",
      "\n",
      " dot product between aigenvectors: 0.9999999999999998 0.0 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "#Eigendecomposition\n",
    "from numpy.linalg import eig\n",
    "values,vectors=eig(S)\n",
    "print('eigenvectors \\n', vectors, '\\n eigenvalues \\n',values)\n",
    "\n",
    "a=vectors[:,0]\n",
    "b=vectors[:,1]\n",
    "print('\\n dot product between aigenvectors:' , np.dot(a,a),np.dot(a,b), np.dot(b,b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The eigenvectors form an orthogonal basis in the feature space\n",
    "\n",
    "### Questions\n",
    "1.  Represent geometrically the data $\\mathbf{Z}$ and the eigenvectors\n",
    "1.  Write the code to show that  $ \\mathbf{S}=\\mathbf{U}\\mathbf{\\Lambda} \\mathbf{U}^T$. Where  $\\mathbf{U}$ is the matrix of eigenvectors and $\\mathbf{\\Lambda}$ is a diagonal matrix with the eigenvalues.\n",
    "2.  Project the centered data matrix into the direction of the largest eigenvalue. First do the calculations and then write the code.\n",
    "_ _Remark: the value of the projection for $n-th$ example $\\mathbf{z}_n$ is calculated  as $a_n=\\mathbf{u}^T\\mathbf{z}_n$, where $\\mathbf{u}$ is the selected eigenvector _ _\n",
    "3.  Reconstruct the data \n",
    "$\\hat{\\mathbf{z}}_n=a_n \\mathbf{u} $.  \n",
    "4.  Compute the squared error,   between the reconstructed $\\hat{\\mathbf{z}}$ and the original, in your data set. Can you antecipate the value of this error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,vectors=eig((1/4)*S)\n",
    "print('eigenvectors', vectors, '\\n eigenvalues',values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "1. What is the difference between the eigendecompostion of $\\mathbf{S}$ and $\\frac{\\mathbf{S}}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel matrix or dot product matrix\n",
    "K=np.dot(Z,Z1)\n",
    "K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions \n",
    "1.  What is the dimension of the matrix $\\mathbf{K}$? Write down an expression to describe its calculation.\n",
    "2.  Write an expression that describes the calculation of one the entries of the matrix $\\mathbf{K}_{i,j}$. What is the meaning of the expression.\n",
    "3. Show that $\\mathbf{K}= \\mathbf{V}\\mathbf{\\Lambda} \\mathbf{V}^T$. Where  $\\mathbf{V}$ is the matrix of eigenvectors and $\\mathbf{\\Lambda}$ is a diagonal matrix with the eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The non-zeros eigenvalues of the matrix have the same values as the eigenvalues of the scatter matrix\n",
    "values,vectors=eig(K)\n",
    "print('eigenvectors', vectors, '\\n eigenvalues',values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(vectors[:,0],vectors[:,0]))\n",
    "print(np.dot(vectors[:,0],vectors[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left eigenvectors [[ 0.19543951  0.51166727  0.7472136  -0.3763932 ]\n",
      " [-0.82789504  0.12078826  0.3472136   0.4236068 ]\n",
      " [ 0.12078826 -0.82789504  0.5472136   0.0236068 ]\n",
      " [ 0.51166727  0.19543951  0.1472136   0.8236068 ]]\n",
      "singular values [2.68999405 1.66250775]\n",
      " right eigenvectors [[-0.52573111 -0.85065081]\n",
      " [-0.85065081  0.52573111]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import svd\n",
    "\n",
    "v,d,u=svd(Z)\n",
    "print('left eigenvectors', v)\n",
    "print('singular values' ,d)\n",
    "print(' right eigenvectors', u)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.236067977499788, 2.7639320225002106]\n"
     ]
    }
   ],
   "source": [
    "### Eigenvalues and Singular values.\n",
    "\n",
    "print(list(np.array(d)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "Given the centered data $\\mathbf{Z}$\n",
    "1.  The left eigenvectors of svd are the eigenvectors of the kernel matrix\n",
    "2.  The right eigenvectors of the svd  are the eigenvectors of the scatter matrix \n",
    "3.  The (non-zero) eigenvalues of kernel and scatter matrix are the square of the singular values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL remark\n",
    "\n",
    "## Singular value decomposition\n",
    "An $ N \\times D$ matrix, where N is the number of examples and $D$ is the dimension of the feature vector, is \n",
    "$$\n",
    "\\mathbf{Z}= \\mathbf{V} \\mathbf{D} \\mathbf{U}^T\n",
    "$$\n",
    "\n",
    "* The matrices of eigenvectors have orthogonal columns\n",
    "* the maximum number of non-zero singular values is $ \\min(N,D)$\n",
    "\n",
    "## Eigendecomposition of  the $D \\times D $ scatter matrix\n",
    "$$\n",
    "\\mathbf{S}=\\mathbf{U}\\mathbf{\\Lambda} \\mathbf{U}^T\n",
    "$$\n",
    "\n",
    "## Eigendecomposition of  the $N \\times N$ kernel matrix\n",
    "$$\n",
    "\\mathbf{K}=\\mathbf{V}\\mathbf{\\Lambda^{(+)}} \\mathbf{V}^T \n",
    "$$\n",
    "\n",
    "* the diagonal matrix  $\\mathbf{\\Lambda^{(+)}}$ has only $D$ elements non zero and are equal to ones the ones in the diagonal of $\\mathbf{\\Lambda}$\n",
    "\n",
    "**Finally diagonal entries of $\\mathbf{\\Lambda} $ are the square of the diagonal entries of $\\mathbf{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
